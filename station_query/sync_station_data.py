#!/usr/bin/env python3
"""
ç«™ç‚¹æ•°æ®åŒæ­¥è„šæœ¬
ä» ONLINE2 ç”Ÿäº§ç¯å¢ƒåŒæ­¥ç«™ç‚¹è¡¨åˆ° TEST ç¯å¢ƒ
"""

import requests
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("StationSync")


class StationSync:
    """ç«™ç‚¹æ•°æ®åŒæ­¥å™¨"""
    
    # å¸‚åœºåˆ—è¡¨
    MARKETS = ['sg', 'id', 'my', 'th', 'ph', 'vn', 'tw', 'br']
    
    def __init__(self):
        # æºç¯å¢ƒ (ONLINE2 ç”Ÿäº§)
        self.source = {
            'host': '10.180.129.96',
            'port': 8123,
            'user': 'spx_mart',
            'password': 'RtL3jHWkDoHp',
            'database': 'spx_mart_manage_app',
            'use_https': False
        }
        
        # ç›®æ ‡ç¯å¢ƒ (TEST)
        self.target = {
            'host': 'clickhouse-k8s-sg-prod.data-infra.shopee.io',
            'port': 443,
            'user': 'spx_mart-cluster_szsc_data_shared_online',
            'password': 'RtL3jHWkDoHp',
            'database': 'spx_mart_pub',
            'use_https': True
        }
    
    def _get_url(self, config):
        """æ„å»º URL"""
        protocol = 'https' if config['use_https'] else 'http'
        return f"{protocol}://{config['host']}:{config['port']}/"
    
    def _execute_query(self, config, sql, timeout=30):
        """æ‰§è¡ŒæŸ¥è¯¢"""
        url = self._get_url(config)
        try:
            response = requests.post(
                url,
                params={
                    'user': config['user'],
                    'password': config['password'],
                    'database': config['database']
                },
                data=sql.encode('utf-8'),
                verify=False,
                timeout=timeout
            )
            return response.status_code == 200, response.text
        except Exception as e:
            return False, str(e)
    
    def test_connections(self):
        """æµ‹è¯•æºå’Œç›®æ ‡ç¯å¢ƒçš„è¿æ¥"""
        logger.info("ğŸ”Œ æµ‹è¯•è¿æ¥...")
        
        # æµ‹è¯•æºç¯å¢ƒ
        logger.info("  æµ‹è¯• ONLINE2 (æº)...")
        success, _ = self._execute_query(self.source, "SELECT 1", timeout=5)
        if success:
            logger.info("  âœ… ONLINE2 è¿æ¥æˆåŠŸ")
        else:
            logger.warning("  âš ï¸  ONLINE2 è¿æ¥å¤±è´¥ (å¯èƒ½éœ€è¦å†…ç½‘/VPN)")
            return False
        
        # æµ‹è¯•ç›®æ ‡ç¯å¢ƒ
        logger.info("  æµ‹è¯• TEST (ç›®æ ‡)...")
        success, _ = self._execute_query(self.target, "SELECT 1", timeout=5)
        if success:
            logger.info("  âœ… TEST è¿æ¥æˆåŠŸ")
        else:
            logger.error("  âŒ TEST è¿æ¥å¤±è´¥")
            return False
        
        return True
    
    def sync_market(self, market):
        """åŒæ­¥å•ä¸ªå¸‚åœºçš„ç«™ç‚¹æ•°æ®"""
        source_table = f"{self.source['database']}.dim_spx_station_tab_{market}_all"
        target_table = f"{self.target['database']}.dim_spx_station_tab_{market}_all"
        
        logger.info(f"ğŸ“Š åŒæ­¥ {market.upper()} å¸‚åœº...")
        
        try:
            # 1. è·å–æºè¡¨æ•°æ®é‡
            sql_count = f"SELECT count() as cnt FROM {source_table}"
            success, result = self._execute_query(self.source, sql_count + " FORMAT TabSeparated")
            if not success:
                logger.error(f"  âŒ è·å–æºè¡¨æ•°æ®é‡å¤±è´¥: {result}")
                return False, 0
            
            source_count = int(result.strip())
            logger.info(f"  æºè¡¨è®°å½•æ•°: {source_count}")
            
            # 2. æ¸…ç©ºç›®æ ‡è¡¨
            logger.info(f"  æ¸…ç©ºç›®æ ‡è¡¨...")
            sql_truncate = f"TRUNCATE TABLE {target_table}"
            success, result = self._execute_query(self.target, sql_truncate)
            if not success:
                logger.error(f"  âŒ æ¸…ç©ºç›®æ ‡è¡¨å¤±è´¥: {result}")
                return False, 0
            
            # 3. ä½¿ç”¨ INSERT SELECT åŒæ­¥æ•°æ®
            logger.info(f"  å¼€å§‹åŒæ­¥æ•°æ®...")
            start_time = time.time()
            
            # æ„å»ºè¿œç¨‹æŸ¥è¯¢ SQL
            source_url = self._get_url(self.source)
            sql_sync = f"""
            INSERT INTO {target_table}
            SELECT * FROM remote(
                '{self.source['host']}:{self.source['port']}',
                '{source_table}',
                '{self.source['user']}',
                '{self.source['password']}'
            )
            """
            
            success, result = self._execute_query(self.target, sql_sync, timeout=300)
            elapsed = time.time() - start_time
            
            if not success:
                logger.error(f"  âŒ æ•°æ®åŒæ­¥å¤±è´¥: {result[:200]}")
                return False, 0
            
            # 4. éªŒè¯æ•°æ®é‡
            sql_verify = f"SELECT count() as cnt FROM {target_table} FORMAT TabSeparated"
            success, result = self._execute_query(self.target, sql_verify)
            if success:
                target_count = int(result.strip())
                logger.info(f"  âœ… åŒæ­¥å®Œæˆ: {target_count} æ¡è®°å½•, è€—æ—¶ {elapsed:.2f}s")
                return True, target_count
            else:
                logger.warning(f"  âš ï¸  åŒæ­¥å®Œæˆä½†éªŒè¯å¤±è´¥")
                return True, source_count
        
        except Exception as e:
            logger.error(f"  âŒ åŒæ­¥å¼‚å¸¸: {e}")
            return False, 0
    
    def sync_all(self, markets=None, max_workers=4):
        """åŒæ­¥æ‰€æœ‰å¸‚åœº"""
        markets_to_sync = markets or self.MARKETS
        
        logger.info(f"ğŸš€ å¼€å§‹åŒæ­¥ {len(markets_to_sync)} ä¸ªå¸‚åœºçš„ç«™ç‚¹æ•°æ®...")
        logger.info(f"   æº: ONLINE2 (ç”Ÿäº§)")
        logger.info(f"   ç›®æ ‡: TEST ç¯å¢ƒ")
        logger.info("")
        
        # æµ‹è¯•è¿æ¥
        if not self.test_connections():
            logger.error("âŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­åŒæ­¥")
            return False
        
        logger.info("")
        
        # å¹¶è¡ŒåŒæ­¥
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(self.sync_market, market): market 
                for market in markets_to_sync
            }
            
            for future in as_completed(futures):
                market = futures[future]
                try:
                    success, count = future.result()
                    results.append((market, success, count))
                except Exception as e:
                    logger.error(f"âŒ {market.upper()} åŒæ­¥å¼‚å¸¸: {e}")
                    results.append((market, False, 0))
        
        # ç»Ÿè®¡ç»“æœ
        elapsed = time.time() - start_time
        success_count = sum(1 for _, success, _ in results if success)
        total_records = sum(count for _, _, count in results)
        
        logger.info("")
        logger.info("=" * 50)
        logger.info(f"âœ… åŒæ­¥å®Œæˆ!")
        logger.info(f"   æˆåŠŸ: {success_count}/{len(markets_to_sync)} ä¸ªå¸‚åœº")
        logger.info(f"   æ€»è®°å½•æ•°: {total_records:,}")
        logger.info(f"   æ€»è€—æ—¶: {elapsed:.2f}s")
        logger.info("=" * 50)
        
        return success_count == len(markets_to_sync)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç«™ç‚¹æ•°æ®åŒæ­¥å·¥å…·')
    parser.add_argument('--markets', type=str, help='æŒ‡å®šå¸‚åœºï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œå¦‚: sg,id,my')
    parser.add_argument('--workers', type=int, default=4, help='å¹¶è¡Œçº¿ç¨‹æ•°')
    
    args = parser.parse_args()
    
    # è§£æå¸‚åœº
    markets = None
    if args.markets:
        markets = [m.strip().lower() for m in args.markets.split(',')]
    
    # æ‰§è¡ŒåŒæ­¥
    syncer = StationSync()
    success = syncer.sync_all(markets=markets, max_workers=args.workers)
    
    exit(0 if success else 1)


if __name__ == '__main__':
    main()
